[{"path":"index.html","id":"welcome","chapter":"1 Welcome","heading":"1 Welcome","text":"satellites field-deployable sensors, entire agricultural environmental landscape increasingly monitored. Advances sensing allow wide range variables measured unprecedented rates scales. large amounts data produced agricultural environmental systems paving way data-intensive methods like machine learning Artificial Intelligence support decision-making natural resources management. opportunities also create new educational needs, particularly among applied scientists engineers may received formal training “data science” methods (Saia et al., 2021), made primer.","code":""},{"path":"index.html","id":"how-to-use-this-primer","chapter":"1 Welcome","heading":"1.1 How to use this primer","text":"primer serves succinct guidebook using machine learning natural resources management. written starting point, comprehensive resource.readers start chapter 2, defines describes “machine learning”. interested developing machine learning models, instead want understand interpret machine learning models critique tools use machine learning, continue reading chapters 3 4. interested seeing example workflow developing machine learning model, skip chapter 5.","code":""},{"path":"index.html","id":"learning-how-to-code","chapter":"1 Welcome","heading":"1.2 Learning how to code","text":"interested developing machine learning models, material presented primer help show start. chapter 5, include example using code prepared R, open source statistical software environment. learn coding R, recommend R Data Science.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"1 Welcome","heading":"1.3 Acknowledgements","text":"Support primer provided U.S. Department Agriculture National Institute Food Agriculture grant number 2019-67021-29936.","code":""},{"path":"index.html","id":"citation","chapter":"1 Welcome","heading":"1.4 Citation","text":"Natalie G. Nelson, Shih-Ni Prim, Sheila Saia, Khara Grieger, Anders Huseth (authors vary chapter). 2024. Machine Learning Primer Natural Resources Management, Accessed online via go.ncsu.edu/mlprimer.","code":""},{"path":"index.html","id":"license","chapter":"1 Welcome","heading":"1.5 License","text":"work licensed CC -NC-SA 4.0.","code":""},{"path":"what-is-machine-learning.html","id":"what-is-machine-learning","chapter":"2 What is machine learning?","heading":"2 What is machine learning?","text":"Authors: Natalie G. Nelson, Shih-Ni Prim, Sheila Saia, Khara Grieger, Anders HusethMachine learning methods teach computer models make predictions patterns data (Zhi et al., 2024). find patterns data, many, many mathematical calculations involved. Computers needed develop machine learning models, advances computing gave rise machine learning.","code":""},{"path":"what-is-machine-learning.html","id":"how-is-machine-learning-useful-for-natural-resources-management","chapter":"2 What is machine learning?","heading":"2.1 How is machine learning useful for natural resources management?","text":"Historically, environmental agricultural systems primarily modeled “process-based” “mechanistic” models, models simulate key system processes based underlying physics, chemistry, biology (Haefner 2005). Models often used fill gaps direct measurements various environmental agricultural phenomena. past, collecting type environmental agricultural data grueling, time consuming, done people. Today, variables still require tough tedious work measure, many variables now readily measured sensors automated instruments.\nexample process-based models used, let’s consider flow water open channel. estimating velocity water open channel using process-based approach, may use Manning’s Equation, simulates water velocity function channel’s physical properties like slope cross sectional area. apply Manning’s Equation, take measurements channel’s dimensions.However, machine learning, simulate environmental agricultural variables using underlying processes. Instead, can create model makes predictions patterns data. Machine learning models require measurements response target variable, variable seeking estimate. current example, water velocity channel target variable. also need measurements predictor variables, variables use predict response.one hypothetical example, machine learning model water velocity open channel might make predictions based images instead physical channel properties. camera situated towards channel take time-lapse photos every minutes. machine learning model developed predict water velocity based appearance water images. real-world example , check Chapman et al. (2024), Stage discharge prediction documentary time-lapse imagery, PLoS ONE.create machine learning model, water velocity measurements needed create training set, data used train develop machine learning model. water velocity measurements collected time images, images directly related water velocity measurements (.e., image looks like , water velocity ). predictor variables derived images. machine learning algorithm selected search patterns images – e.g., shading/color individual image pixels, relationships neighboring pixels – water velocity measurements. patterns established, can used estimate water velocity new images collected. Importantly, image-based machine learning model knows nothing underlying physics controlling water velocity channel; simply learned certain patterns images correspond higher lower water velocities.Machine learning models can easily expanded include many different types predictor variables. example, image-based machine learning model water velocity built include additional predictors like rainfall, irrigation, time year. flexibility machine learning models allows consider many diverse streams information learning patterns make predictions. see additional examples machine learning models developed natural resource management applications, see chapter 4.","code":""},{"path":"what-is-machine-learning.html","id":"pros-and-cons","chapter":"2 What is machine learning?","heading":"2.2 Pros and cons","text":"make predictions correlative patterns predictor response variables, machine learning models parallels simpler statistical models like linear regression. However, machine learning models consist hundreds, thousands, millions individual equations, linear regression model consists one equation. many equations, machine learning models commonly considered “black boxes” since peering machine learning model can feel like looking pitch black box – don’t precisely know ’s inside. Methods now exist help us illuminate machine learning black boxes, field “interpretable” “explainable” machine learning made great strides support better understanding inner workings models (Samek et al., 2021). Still, machine learning models substantially challenging interpret model alternatives.challenges interpretation clear pitfall machine learning models, complicated structures allow pick relatively subtle nuanced relationships datasets, making effective predictive tools. many cases, machine learning models outperform process-based models (e.g., predictions can greater accuracy predictions models). ability create strong predictions arguably hallmark strength machine learning. previously described flexibility able include many different diverse data types (e.g., images, sensor data, weather station observations) predictors also key strength. , necessarily account underlying processes, machine learning models risk spurious predictions, particularly developed irresponsibly. chapter 3, include questions can ask evaluate whether model developed responsibly, assess whether vulnerable making spurious predictions.","code":""},{"path":"what-is-machine-learning.html","id":"classes-of-machine-learning-models","chapter":"2 What is machine learning?","heading":"2.3 Classes of machine learning models","text":"previous example image-based predictions water velocity, summarized use supervised learning approach. Simply put, supervised learning true answers model, measurements response variable (Sarker 2021). water velocity model example, water velocity measurements used model development facilitate learning patterns images specifically used predict water velocity. supervised learning model developed, predictions model can compared measurements assess well model predicts.Unsupervised learning, hand, performs tasks answers model. example, instead using images stream estimate water velocity, unsupervised machine learning model used group cluster images shared similarities. Unsupervised learning often used computer-assisted way exploring patterns data (Sarker 2021). Sometimes, groups clusters uncovered unsupervised learning model can assigned labels use modeling analysis efforts.","code":""},{"path":"what-is-machine-learning.html","id":"an-example-of-supervised-and-unsupervised-learning","chapter":"2 What is machine learning?","heading":"2.4 An example of supervised and unsupervised learning","text":"National Land Cover Database Dataset (NLCD) created U.S. Geological Survey partners map land cover across contiguous U.S. data updated every years, creating historical record land cover change across country time. 1970s 1980s, land cover mapping performed manually delineating areas aerial photographs. 1992, NLCD premiered land cover data product created Landsat satellite imagery. Landsat imagery pixels 30 meters 30 meters. create 1992 product, NLCD imagery clustered 100 groups using unsupervised learning approach, people evaluated 100 groups manually assigned land cover categories (e.g., forest, developed area). Later, create 2001 NLCD product, supervised learning approach used areas known land cover used train model predict land cover categories based Landsat imagery. Read history NLCD program Chapter 18 Nature Geographic Information (DiBiase et al.).","code":""},{"path":"what-is-machine-learning.html","id":"algorithms","chapter":"2 What is machine learning?","heading":"2.5 Algorithms","text":"Within two broad classifications machine learning (supervised unsupervised), overwhelming number machine learning algorithms, specific computer model frameworks implementing machine learning. sheer number machine learning algorithms attests power versatility. primer catalog different machine learning algorithms. starting point, can see algorithm examples resources .machine learning algorithm use SAS blogsMachine Learning Cheat Sheet Datacamp","code":""},{"path":"what-is-machine-learning.html","id":"a-deeper-dive","chapter":"2 What is machine learning?","heading":"2.6 A deeper dive","text":"like learn machine learning, check Introduction Statistical Learning James et al. (2013). book provides wealth information machine learning models, authors assume readers mainly interested applying, rather deeply studying, machine learning models. four premises offered authors, listed pp 8-9, demonstrate practical focus book:\nMany statistical learning methods relevant useful wide range academic non-academic disciplines, beyond just statistical sciences.\nStatistical learning viewed series black boxes.\nimportant know job performed cog, necessary skills construct machine inside box!\npresume reader interested applying statistical learning methods real-world problems.\nfree PDF versions books available online, examples presented R Python.","code":""},{"path":"key-considerations.html","id":"key-considerations","chapter":"3 Key considerations","heading":"3 Key considerations","text":"Authors: Natalie G. Nelson, Shih-Ni Prim, Sheila Saia, Khara Grieger, Anders HusethHere, offer key questions natural resource management practitioners can ask using developing machine learning model inform day--day decision-making. Importantly, questions based opinions experiences, taken definitive criteria. questions provided help start thinking critically process using machine learning model outputs.machine learning model used instead process-based model easily interpretable statistical model?process-based mechanistic models capture underlying physical, biological, chemical processes driving agricultural environmental phenomena, , theory, less vulnerable making spurious predictions compared machine learning models. However, process-based model development often time- resource-intensive, agricultural environmental phenomena well predicted explained process-based models. Generally, system dominated physical processes, predictable system’s behaviors process-based models (Haefner 2005); physical processes often well represented established mathematical formulations. hand, behaviors largely driven system biology ecology, process-based models can poor performance biological ecological processes challenging robustly accurately represent mathematical equations. example, reasonable assume easier simulate changes lake’s water levels amount algae lake.cases physical process-based model developed instead machine learning model, reasonable question whether machine learning model suitable support decision-making. Similarly, easily interpretable model like linear regression model can used adequate performance, generally preferable, model users greater understanding model operates.much data needed develop machine learning model?minimum dataset size developing machine learning model, machine learning models generally developed large datasets (e.g., thousands millions data points). Since machine learning models learn patterns data, enough data patterns can learned. Importantly, data also high accuracy ensure machine learning model developed quality information. dataset size requirements, environmental agricultural systems, often see machine learning models developed data sensors imagery, data collection systems produce large volumes data.data used train model?probably important question ask. machine learning models make predictions patterns data, data provided train model dictate types predictions machine learning model can make. training dataset narrow (e.g., includes short time period, time period little environmental variation, limited number locations, etc.), predictions generalize. machine learning model developed data corn fields Midwest, predictions apply corn fields Georgia? particular, ask (model developers), missing training data? example, ’re interested predicting effects drought, many drought periods included data, severe droughts? Even training data spatially extensive, think critically whether data may biased disproportionately unrepresentative way data may generalizable.example, research shown surface water quality monitoring Southeast U.S. disproportionately occurs affluent areas (Oates et al., 2024), meaning areas greater social vulnerability fewer monitoring stations. machine learning model developed using available water quality data Southeast purpose predicting water quality unmonitored areas, might sound though training data comprehensive region, model ultimately affected training data’s underlying bias. model developer unable disclose data sources (e.g., data ownership/privacy concerns), still able provide information general data characteristics can assess whether training data apply system interest.model tested evaluated? measures uncertainty reported?understand well machine learning model performs, important understand model’s error, difference model’s predictions true measurements. Error can reported many ways. One common metric Root Mean Square Error (RMSE), essentially average model error. RMSE reported units target variable, making useful interpret. Metrics like coefficient determination, R2, also commonly reported. Learn commonly used error metrics . Understanding model’s error key assessing accuracy reliability. addition error, modelers ideally report measures uncertainty. Uncertainty describes range plausible model outcomes. example, let’s say running machine learning model can predict daily plant water demand one predictors rainfall. expect 1-1.5” rain today, run plant water demand model 1” rain today, 1.5” rain. plausible. run model two scenarios, difference predicted plant water demand described uncertainty model output. Consideration uncertainty hallmark sign responsible modeling.model developers transparent limitations model performance?wary salesmanship. Responsible modelers clearly articulate limitations training data, aspects poor model performance. model developer able tell model effective predicting different types outcomes.modelers choose predictors? seem understand underlying science processes agricultural environmental system making predictions ?Ideally, predicting agricultural environmental system behaviors machine learning model, sound scientific reasoning regarding selection predictors. Judicious selection predictors can also help avoid spurious predictions.modelers know predictor importance?machine learning model developed, methods available identifying predictors carry weight, “important”, model. can helpful understand predictors important, can use understanding environmental agricultural system dynamics corroborate whether variables importance make sense. obscure variable important model, ’s reasonable question , whether importance obscure predictor negatively affect model performance.outputs model used?Machine learning models used replace human decision-making natural resources management, can instead used supportive tool. Machine learning models can synthesize lot information identify patterns readily interpretable average person, making great decision-support tools. However, keep mind training data almost always biased way, biases propagate predictions.model run, outputs shared?Developing machine learning model creating user-friendly system applying /accessing outputs machine learning model entirely different tasks. cases, model can developed shared via computer code, end users may struggle run model using provided computer code, depending familiarity programming. working partner (e.g., university, consulting group) produce model, ensure plan transitioning model can use ease. team created resource interested creating apps disseminating models, Ten Simple Rules Researchers Want Develop Web Apps, may provide helpful tips team interested exploring use web apps model model output dissemination.","code":""},{"path":"case-studies.html","id":"case-studies","chapter":"4 Case studies","heading":"4 Case studies","text":"Authors: Natalie G. Nelson Shih-Ni PrimTo illustrate use machine learning across diverse natural resource management applications, three case studies presented , use machine learning modeling framework. three case studies include models predicting (1) daily pluvial flood dynamics agricultural landscapes, (2) fecal coliform exceedances shellfish growing waters, (3) sweetpotato yields county-scale. three models use Random Forest, specific type machine learning algorithm. Random Forest creates many (e.g., hundreds thousands) regression classification trees predict categories continuous values response variable. Random Forest considered particularly effective algorithm working environmental agricultural data, can effectively capture nonlinear complex interactions variables. three case studies offer interpretations important predictor variables model, explanations predictors may important.","code":""},{"path":"case-studies.html","id":"daily-pluvial-flood-prediction","chapter":"4 Case studies","heading":"4.1 1: Daily pluvial flood prediction","text":"Machine learning approach modeling daily pluvial flood dynamics agricultural landscapes (Fidan et al., 2023)Response variable: Binary categories “flooded” “flooded”Predictor variables: Soil characteristics (flood frequency, drainage class), elevation, height nearest drainage, slope, topographic wetness index, distance nearest stream, distance nearest road, population, multi-day precipitationIn study, model developers focused agricultural area experienced pluvial, rain-driven, flooding following major hurricane. area treated grid, grid divided square pixels equal area. model developed estimate likelihood pixel flooded flooded based landscape characteristics (e.g., soils, land cover type), recent rainfall patterns.Read full study .","code":""},{"path":"case-studies.html","id":"fecal-coliform-forecasting","chapter":"4 Case studies","heading":"4.2 2: Fecal coliform forecasting","text":"Short-term forecasting fecal coliforms shellfish growing waters (Chazal et al., 2024)Response variable: Fecal coliform (bacteria) concentrationsPredictor variables: Rainfall, river stage, wind speed direction, lengths artificial natural channelization, land use land cover, soil drainage class, air water temperatures, month (.e., time year)study, model developers used long-term monitoring data Florida Department Agriculture Consumer Services shellfish sanitation program. monitoring data collected specific sampling locations across coast Florida shellfish grown harvest. model developed predict likelihood fecal coliform (.e., bacteria) concentration exceedance station routine monitoring data collected. Predictors model included range variables explain source transport bacteria, well factors affect survivability bacteria water (e.g., temperature).Read full study .","code":""},{"path":"case-studies.html","id":"in-season-sweetpotato-yield-forecasting","chapter":"4 Case studies","heading":"4.3 3: In-season sweetpotato yield forecasting","text":"-season Sweetpotato Yield Forecasting using Multitemporal Remote Sensing Environmental Observations Machine Learning (Carbajal Carrasco et al., 2024)Response variable: Sweetpotato yields county scale, reported USDA National Agricultural Statistics ServicePredictor variables: Elevation, slope, aspect, soil characteristics (% clay, % sand, pH, cation exchange capacity, bulk density, nitrogen, organic carbon), rainfall, maximum temperature, minimum temperature, Normalized Difference Vegetation Index calculated satellite imagery (Landsat Sentinel-2)study, model developed predict end--season sweetpotato yields county scale using early season predictors, model can used forecast harvested yields early growing season. model uses range predictors capture climatic physical properties influence sweetpotato yields large spatial scales, account cultural management practices.Read full study . Note study currently undergoing peer review, findings considered preliminary.","code":""},{"path":"workflow.html","id":"workflow","chapter":"5 Workflow demonstration","heading":"5 Workflow demonstration","text":"Authors: Shih-Ni PrimIn section, use dataset exemplify typical workflow constructing machine learning models. skip exploratory data analysis, process exploring data understand structure components, exploration always occur prior modeling. exploratory data analysis, refer Chapter 4 Exploratory Data Analysis Art Data Science Roger D. Peng Elizabeth Matsui.dataset analyzed contains wine quality traits, goal predict quality wine using traits. dataset can found .","code":"\nknitr::opts_chunk$set(echo = TRUE, eval = TRUE, cache = TRUE)\nlibrary(tree)\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(rattle)\nlibrary(randomForest)"},{"path":"workflow.html","id":"prepare-the-data","chapter":"5 Workflow demonstration","heading":"5.1 Prepare the data","text":"first read data rename variables, coding easier., ’ll develop Random Forest model, machine learning algorithm used develop models presented Chapter 4. demonstrate construct Random Forest model continuous discrete outcomes, also transform continuous variable, wine quality (response variable) two discrete variables. One two levels (high vs low), one three levels (H, M, L). thresholds decided rather arbitrarily, can use domain knowledge gauge set thresholds.Next, randomly separate dataset training set (80% rows) testing set (20% rows). seed set result can reproduced.","code":"\nwine <- read_delim(\"materials/winequality-red.csv\", delim = ';')## Rows: 1599 Columns: 12\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## dbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n# shorten variable names\nfa <- wine$`fixed acidity`\nva <- as.numeric(wine$`volatile acidity`)\nca <- as.numeric(wine$`citric acid`)\nrs <- wine$`residual sugar`\nch <- as.numeric(wine$chlorides)\nfsd <- wine$`free sulfur dioxide`\ntsd <- wine$`total sulfur dioxide`\nden <- as.numeric(wine$density)\nph <- wine$pH\nsul <- as.numeric(wine$sulphates)\nal <- wine$alcohol\nqual <- wine$quality\nwinez <- data.frame(fa, va, ca, rs, ch, fsd, tsd, den, ph, sul, al, qual)\n# collapse qual into 2 labels\nwinez$qual2 <- as.factor(ifelse(winez$qual < 6, \"low\", \"high\"))\n# collapse qual into 3 labels\nwinez$qual3 <- as.factor(ifelse(winez$qual < 5, \"L\", ifelse(winez$qual < 7, \"M\", \"H\")))\ntable(qual)## qual\n##   3   4   5   6   7   8 \n##  10  53 681 638 199  18\ntable(winez$qual2)## \n## high  low \n##  855  744\ntable(winez$qual3)## \n##    H    L    M \n##  217   63 1319\n# separate data into a training set and a test set \nset.seed(2)\ntrain <- sample(nrow(winez), nrow(winez)*0.8)\nwinez_train <- winez[train,]\nwinez_test <- winez[-train,]"},{"path":"workflow.html","id":"classification-model","chapter":"5 Workflow demonstration","heading":"5.2 Classification model","text":"Now, construct Random Forest model two-level response. model run, calculate predictions using predict function. plot important predictors model provided. can see alcohol, sulphates, volatile acidity three important predictors outcome variable. confusion matrix created, shows different metrics overall accuracy rate, sensitivity, specificity, etc.Next, create model three-level outcome variable. , important predictors plotted confusion matrix included . alcohol, volatile acidity, sulphates three important predictors, order changed. overall accuracy higher two-level model.plot shows accuracy rate changes number randomly selected variables tree (denoted \\(m\\)).\nFigure 5.1: Accuracy Rates vs Number Predictors Used 2-level Variable (left) 3-level Variable (right)\n","code":"\n# random forest\nrfGrid <- expand.grid(mtry = 2:8)\n# 2-level variable\nrf_tree2 <- train(qual2 ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, method = \"rf\", preProcess = c(\"center\", \"scale\"), trControl = trainControl(method = \"cv\", number = 10), tuneGrid = rfGrid)\nrf2_pred <- predict(rf_tree2, newdata = winez_test)\nrfMatrix2 <- table(rf2_pred, winez_test$qual2)\nrf2_test <- mean(rf2_pred == winez_test$qual2)\nplot(varImp(rf_tree2))\nconfusionMatrix(rf2_pred, winez_test$qual2)## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction high low\n##       high  138  25\n##       low    45 112\n##                                           \n##                Accuracy : 0.7812          \n##                  95% CI : (0.7319, 0.8253)\n##     No Information Rate : 0.5719          \n##     P-Value [Acc > NIR] : 2.968e-15       \n##                                           \n##                   Kappa : 0.5613          \n##                                           \n##  Mcnemar's Test P-Value : 0.02315         \n##                                           \n##             Sensitivity : 0.7541          \n##             Specificity : 0.8175          \n##          Pos Pred Value : 0.8466          \n##          Neg Pred Value : 0.7134          \n##              Prevalence : 0.5719          \n##          Detection Rate : 0.4313          \n##    Detection Prevalence : 0.5094          \n##       Balanced Accuracy : 0.7858          \n##                                           \n##        'Positive' Class : high            \n## \n# 3-level variable\nrf_tree3 <- train(qual3 ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, method = \"rf\", preProcess = c(\"center\", \"scale\"), trControl = trainControl(method = \"cv\", number = 10), tuneGrid = rfGrid)\nrf3_pred <- predict(rf_tree3, newdata = winez_test)\nrfMatrix3 <- table(rf3_pred, winez_test$qual3)\nrf3_test <- mean(rf3_pred == winez_test$qual3)\nplot(varImp(rf_tree3))\nconfusionMatrix(rf3_pred, winez_test$qual3)## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction   H   L   M\n##          H  25   0   5\n##          L   0   0   1\n##          M  18   8 263\n## \n## Overall Statistics\n##                                           \n##                Accuracy : 0.9             \n##                  95% CI : (0.8618, 0.9306)\n##     No Information Rate : 0.8406          \n##     P-Value [Acc > NIR] : 0.001473        \n##                                           \n##                   Kappa : 0.5617          \n##                                           \n##  Mcnemar's Test P-Value : NA              \n## \n## Statistics by Class:\n## \n##                      Class: H Class: L Class: M\n## Sensitivity           0.58140 0.000000   0.9777\n## Specificity           0.98195 0.996795   0.4902\n## Pos Pred Value        0.83333 0.000000   0.9100\n## Neg Pred Value        0.93793 0.974922   0.8065\n## Prevalence            0.13437 0.025000   0.8406\n## Detection Rate        0.07812 0.000000   0.8219\n## Detection Prevalence  0.09375 0.003125   0.9031\n## Balanced Accuracy     0.78167 0.498397   0.7339\n# random forest plot: accuracy rates vs number of predictors\nrfplot1 <- plot(rf_tree2)\nrfplot2 <- plot(rf_tree3)\ngridExtra::grid.arrange(rfplot1, rfplot2, nrow = 1, ncol = 2)"},{"path":"workflow.html","id":"continuous-model","chapter":"5 Workflow demonstration","heading":"5.3 Continuous model","text":"Next, construct Random Forest models continuous outcome variable. first set \\(m\\) square root number predictors, commonly recommended. Confusion matrices provided continuous responses, can calculate mean squared error (MSE), find important variables, show error decreases number trees constructed. three important variables alcohol, sulphates, volatile acidity.try several different values number variables included tree. alcohol, sulphates, volatile acidity remain three important predictors. Two plots provided show error decreases number trees.Lastly, put MSEs models together. differences small, model uses \\(m=\\sqrt{p}\\) slightly lower MSE.","code":"\n# randomforests, mtry = sqrt(11)\nrf.def.Wine <- randomForest(qual ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, importance = TRUE)\nyhat.rf.Wine <- predict(rf.def.Wine, newdata = winez_test)\nrf.mtry3.testMSE <- mean((yhat.rf.Wine - winez_test$qual)^2)\nvarImp(rf.def.Wine)##      Overall\n## fa  22.11429\n## va  37.04878\n## ca  23.74687\n## rs  18.55913\n## ch  24.96786\n## fsd 21.65164\n## tsd 32.28444\n## den 27.19701\n## ph  22.36903\n## sul 43.52900\n## al  54.53284\nplot(rf.def.Wine)\n# mtry = 4\nrf.def.Wine.m4 <- randomForest(qual ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, mtry = 4, importance = TRUE)\nrf.pred.m4 <- predict(rf.def.Wine.m4, newdata = winez_test)\nrf.mtry4.testMSE <- mean((rf.pred.m4 - winez_test$qual)^2)\nvarImp(rf.def.Wine.m4)##      Overall\n## fa  22.78226\n## va  39.40868\n## ca  22.22551\n## rs  16.27685\n## ch  25.12775\n## fsd 21.58168\n## tsd 30.36789\n## den 27.20655\n## ph  20.22223\n## sul 47.59070\n## al  60.54909\n# mtry = 7\nrf.def.Wine.m7 <- randomForest(qual ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, mtry = 7, importance = TRUE)\nrf.pred.m7 <- predict(rf.def.Wine.m7, newdata = winez_test)\nrf.mtry7.testMSE <- mean((rf.pred.m7 - winez_test$qual)^2)\nvarImp(rf.def.Wine.m7)##      Overall\n## fa  22.31197\n## va  43.85162\n## ca  22.34412\n## rs  15.79913\n## ch  26.89172\n## fsd 22.86225\n## tsd 35.73985\n## den 28.37794\n## ph  24.39275\n## sul 55.85386\n## al  71.99840\npar(mfrow = c(1, 2))\nplot(rf.def.Wine.m4)\nplot(rf.def.Wine.m7)\nres <- data.frame(rf.mtry3.testMSE, rf.mtry4.testMSE, rf.mtry7.testMSE)\ncolnames(res) <- c(\"squre root of p\", \"4\", \"7\")\nrownames(res) <- c(\"MSE\")\nknitr::kable(res)"}]
